######################################################################################################
# Import packages
######################################################################################################

import numpy as np
import matplotlib.pyplot as plt
# from MDPlib import MDP

######################################################################################################
# Global constant settings
######################################################################################################

FALSE = 0
TRUE = 1

######################################################################################################
# Definition of classes and functions
######################################################################################################

def powerset(s):
	power_set=[[]]
	for elem in s:
	# iterate over the sub sets so far
		for sub_set in power_set:
      		# add a new subset consisting of the subset at hand added elem
      			power_set=power_set+[list(sub_set)+[elem]]
	return power_set

class MDP():
	"""A simple MDP """
	
	def __init__(self, StateList, ActionSet, TransitionMatrix, Reward, Discount):
		"""Init MDP"""      	
		self._states = StateList
		self._Nstates = np.size(StateList)
		self._transitionmatrix = TransitionMatrix

	def print_stateinfo(self):
		print(self._states)
		print('Number of states: {}'.format(self._Nstates))

	def print_transitioninfo(self):
		print(self._transitionmatrix)

	def get_state_valuation():
		pass

######################################################################################################
### Parameter settings
######################################################################################################

LIMIT = 4.0
GOAL_STEPS = 5
POLICY1 = 'random search'
POLICY2 = 'fixed'
CONSOLE = TRUE
NOCONSOLE = FALSE
QUESTIONS = ('Q1', 'Q2', 'Q3', 'Q4')



###############################################################################################
# The transition matrices are defined similarly to the lecture:

#                       to
#              [[ 0, 0, 0, 0, 0],
#		[ 0, 0, 0, 0, 0],
#	from	[ 0, 0, 0, 0, 0],
#		[ 0, 0, 0, 0, 0],
#		[ 0, 0, 0, 0, 0]]


# Transition matrix for action: "Try to solve Task 1"

			 #0  1  2  3  4  5  6  7  8  9  A  B  C  D  E  F
PROB_MATRIX_A1 =       [[.9,.1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],#0
			[ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],#1
			[ 0, 0,.9,.1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],#2
			[ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],#3
			[ 0, 0, 0, 0,.9,.1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],#4
			[ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],#5
			[ 0, 0, 0, 0, 0, 0,.9,.1, 0, 0, 0, 0, 0, 0, 0, 0],#6
			[ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],#7
			[ 0, 0, 0, 0, 0, 0, 0, 0,.9,.1, 0, 0, 0, 0, 0, 0],#8
			[ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],#9
			[ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,.9,.1, 0, 0, 0, 0],#10
			[ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],#11
			[ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,.9,.1, 0, 0],#12
			[ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],#13
			[ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,.9,.1],#14
			[ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]]#15


# Transition matrix for action: "Try to solve Task 2"
			 #0  1  2  3  4  5  6  7  8  9  A  B  C  D  E  F
PROB_MATRIX_A2 =       [[.2, 0,.8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],#0
			[ 0,.2, 0,.8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],#1
			[ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],#2
			[ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],#3
			[ 0, 0, 0, 0,.2, 0,.8, 0, 0, 0, 0, 0, 0, 0, 0, 0],#4
			[ 0, 0, 0, 0, 0,.2, 0,.8, 0, 0, 0, 0, 0, 0, 0, 0],#5
			[ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],#6
			[ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],#7
			[ 0, 0, 0, 0, 0, 0, 0, 0,.2, 0,.8, 0, 0, 0, 0, 0],#8
			[ 0, 0, 0, 0, 0, 0, 0, 0, 0,.2, 0,.8, 0, 0, 0, 0],#9
			[ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],#10
			[ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],#11
			[ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,.2, 0,.8, 0],#12
			[ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,.2, 0,.8],#13
			[ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],#14
			[ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]]#15


# Transition matrix for action: "Try to solve Task 3"
			 #0  1  2  3  4  5  6  7  8  9  A  B  C  D  E  F
PROB_MATRIX_A3 =       [[.7, 0, 0, 0,.3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],#0
			[ 0,.7, 0, 0, 0,.3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],#1
			[ 0, 0,.7, 0, 0, 0,.3, 0, 0, 0, 0, 0, 0, 0, 0, 0],#2
			[ 0, 0, 0,.7, 0, 0, 0,.3, 0, 0, 0, 0, 0, 0, 0, 0],#3
			[ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],#4
			[ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],#5
			[ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],#6
			[ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],#7
			[ 0, 0, 0, 0, 0, 0, 0, 0,.7, 0, 0, 0,.3, 0, 0, 0],#8
			[ 0, 0, 0, 0, 0, 0, 0, 0, 0,.7, 0, 0, 0,.3, 0, 0],#9
			[ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,.7, 0, 0, 0,.3, 0],#10
			[ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,.7, 0, 0, 0,.3],#11
			[ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],#12
			[ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],#13
			[ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],#14
			[ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]]#15


# Transition matrix for action: "Try to solve Task 4"
			 #0  1  2  3  4  5  6  7  8  9  A  B  C  D  E  F
PROB_MATRIX_A4 =       [[.5, 0, 0, 0, 0, 0, 0, 0,.5, 0, 0, 0, 0, 0, 0, 0],#0
			[ 0,.5, 0, 0, 0, 0, 0, 0, 0,.5, 0, 0, 0, 0, 0, 0],#1
			[ 0, 0,.5, 0, 0, 0, 0, 0, 0, 0,.5, 0, 0, 0, 0, 0],#2
			[ 0, 0, 0,.5, 0, 0, 0, 0, 0, 0, 0,.5, 0, 0, 0, 0],#3
			[ 0, 0, 0, 0,.5, 0, 0, 0, 0, 0, 0, 0,.5, 0, 0, 0],#4
			[ 0, 0, 0, 0, 0,.5, 0, 0, 0, 0, 0, 0, 0,.5, 0, 0],#5
			[ 0, 0, 0, 0, 0, 0,.5, 0, 0, 0, 0, 0, 0, 0,.5, 0],#6
			[ 0, 0, 0, 0, 0, 0, 0,.5, 0, 0, 0, 0, 0, 0, 0,.5],#7
			[ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],#8
			[ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],#9
			[ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],#10
			[ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],#11
			[ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],#12
			[ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],#13
			[ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],#14
			[ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]]#15

# This multiplier has to be used, because the agent is 'clever' enough to not try to solve the same task twice.

			  #0   1   2   3   4   5   6 7   8   9   A B   C D E   F		
MULTIPLIER =           [0.25,1/3,1/3,0.5,1/3,0.5,0.5,1,1/3,0.5,0.5,1,0.5,1,1,.25]#0


# The state transition matrix is calculated out of the individual transition matrices for each action 
A1 = np.asarray(PROB_MATRIX_A1)
A2 = np.asarray(PROB_MATRIX_A2)
A3 = np.asarray(PROB_MATRIX_A3)
A4 = np.asarray(PROB_MATRIX_A4)
MUL = np.asarray(MULTIPLIER)


PROB_MATRIX = A1 + A2+ A3 +A4

# The transition matrix:
TRANSITION_MATRIX = np.transpose(np.multiply(np.transpose(PROB_MATRIX), MUL))

# A simple check, if the rows sum up to 1
# print(np.sum(PROB_SCALED, axis=1))


# Transition matrix for policy a: 'Start with task with lowest difficulty'
			 #0  1  2  3  4  5  6  7  8  9  A  B  C  D  E  F
PROB_MATRIX_PA =       [[.2, 0,.8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],#0
			[ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],#1
			[ 0, 0,.5, 0, 0, 0, 0, 0, 0, 0,.5, 0, 0, 0, 0, 0],#2
			[ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],#3
			[ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],#4
			[ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],#5
			[ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],#6
			[ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],#7
			[ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],#8
			[ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],#9
			[ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,.7, 0, 0, 0,.3, 0],#10
			[ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],#11
			[ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],#12
			[ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],#13
			[ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,.9,.1],#14
			[ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]#15

# Transition matrix for policy b: 'Start with task with highest difficulty'
			 #0  1  2  3  4  5  6  7  8  9  A  B  C  D  E  F
PROB_MATRIX_PB =       [[.9,.1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],#0
			[ 0,.7, 0, 0, 0,.3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],#1
			[ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],#2
			[ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],#3
			[ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],#4
			[ 0, 0, 0, 0, 0,.5, 0, 0, 0, 0, 0, 0, 0,.5, 0, 0],#5
			[ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],#6
			[ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],#7
			[ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],#8
			[ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],#9
			[ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],#10
			[ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],#11
			[ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],#12
			[ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,.2, 0,.8],#13
			[ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],#14
			[ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]#15

###############################################################################################





			#0 1 2 3 4 5 6 7 8 9 A B C D E F		
REWARD_MATRIX =        [[0,4,1,0,3,0,0,0,2,0,0,0,0,0,0,0],#0
			[0,4,0,1,0,3,0,0,0,2,0,0,0,0,0,0],#1
			[0,0,1,4,0,0,3,0,0,0,2,0,0,0,0,0],#2
			[0,0,0,5,0,0,0,3,0,0,0,2,0,0,0,0],#3
			[0,0,0,0,3,4,1,0,0,0,0,0,2,0,0,0],#4
			[0,0,0,0,0,7,0,1,0,0,0,0,0,2,0,0],#5
			[0,0,0,0,0,0,4,4,0,0,0,0,0,0,2,0],#6
			[0,0,0,0,0,0,0,8,0,0,0,0,0,0,0,2],#7
			[0,0,0,0,0,0,0,0,2,4,1,0,3,0,0,0],#8
			[0,0,0,0,0,0,0,0,0,6,0,1,0,3,0,0],#9
			[0,0,0,0,0,0,0,0,0,0,3,4,0,0,3,0],#10
			[0,0,0,0,0,0,0,0,0,0,0,7,0,0,0,3],#11
			[0,0,0,0,0,0,0,0,0,0,0,0,5,4,1,0],#12
			[0,0,0,0,0,0,0,0,0,0,0,0,0,9,0,1],#13
			[0,0,0,0,0,0,0,0,0,0,0,0,0,0,6,4],#14
			[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,10]]#15

			#0 1 2 3 4 5 6 7 8 9 A B C D E F		
REWARD_MATRIX =        [[0,4,1,0,3,0,0,0,2,0,0,0,0,0,0,0],#0
			[0,0,0,1,0,3,0,0,0,2,0,0,0,0,0,0],#1
			[0,0,0,4,0,0,3,0,0,0,2,0,0,0,0,0],#2
			[0,0,0,0,0,0,0,3,0,0,0,2,0,0,0,0],#3
			[0,0,0,0,0,4,1,0,0,0,0,0,2,0,0,0],#4
			[0,0,0,0,0,0,0,1,0,0,0,0,0,2,0,0],#5
			[0,0,0,0,0,0,0,4,0,0,0,0,0,0,2,0],#6
			[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2],#7
			[0,0,0,0,0,0,0,0,0,4,1,0,3,0,0,0],#8
			[0,0,0,0,0,0,0,0,0,0,0,1,0,3,0,0],#9
			[0,0,0,0,0,0,0,0,0,0,0,4,0,0,3,0],#10
			[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3],#11
			[0,0,0,0,0,0,0,0,0,0,0,0,0,4,1,0],#12
			[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1],#13
			[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4],#14
			[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]]#15

DISCOUNT = 1

# Expected reward of the next state given the actual state and an action
# REWARD = [np.dot(TRANSITION_MATRIX,np.transpose(REWARD_MATRIX)]
# stateList = np.arrange(Questions)

EXPECTED_REWARD = np.sum(np.multiply(TRANSITION_MATRIX, REWARD_MATRIX), axis=1)

print('Expected reward: {}'.format(EXPECTED_REWARD))



######################################################################################################
### Main starts here
######################################################################################################

student_MDP = MDP(powerset(QUESTIONS), 1, TRANSITION_MATRIX, EXPECTED_REWARD, DISCOUNT)
#student_MDP = MDP(powerset(QUESTIONS), 1, PROB_MATRIX_PA, EXPECTED_REWARD, DISCOUNT)

I = np.identity(np.size(powerset(QUESTIONS))) #16x16 identity
#print(I)
B = I-(PROB_MATRIX_PA)
#print(B)
C = np.linalg.inv(B)
v = np.dot(C, EXPECTED_REWARD)
print('Value function: {}'.format(v))
#student_MDP.print_stateinfo()
#student_MDP.print_transitioninfo()

######################################################################################################
# Code dumpster
######################################################################################################

#			 #0  1  2  3  4  5  6  7  8  9  A  B  C  D  E  F
#PROB_MATRIX_A0 =       [[ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],#0
#			[ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],#1
#			[ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],#2
#			[ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],#3
#			[ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],#4
#			[ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],#5
#			[ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],#6
#			[ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],#7
#			[ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],#8
#			[ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],#9
#			[ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],#10
#			[ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],#11
#			[ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],#12
#			[ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],#13
#			[ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],#14
#			[ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]#15

			#0 1 2 3 4 5 6 7 8 9 A B C D E F
#TRANSITION_MATRIX =    [[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],#0
#			[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],#1
#			[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],#2
#			[0,0,0,0,0,0,0,0.15,0,0,0,0,0,0,0,0],#3
#			[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],#4
#			[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],#5
#			[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],#6
#			[0,0,0,0,0,0,0,0.5,0,0,0,0,0,0,0,0.5],#7
#			[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],#8
#			[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],#9
#			[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],#10
#			[0,0,0,0,0,0,0,0,0,0,0,0.7,0,0,0,0.3],#11
#			[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],#12
#			[0,0,0,0,0,0,0,0,0,0,0,0,0,0.2,0,0.8],#13
#			[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0.9,0.1],#14
#			[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1]]#15
